\documentclass[12pt]{article}
\usepackage[margin=2cm]{geometry}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}

\setlist{nosep} % or \setlist{noitemsep} to leave space around whole list

\title{Machine Learning Intermediate Project Report}
\author{
  CS 6350 Machine Learning \\
  Jackson Pontsler, Michael Bentley
  }
\date{}

\begin{document}

\maketitle

\section{Problem}

Develop a machine learning algorithm that can classify a few of the classification fields of a handwritten census record.  Such classification fields may be gender, ethnicity, or marital status.

\section{What has been done}

We have contacted Family Services of the Church of Jesus Christ of Latter-Day Saints to gather labeled and unlabeled scanned images.  We have signed and returned their non-disclosure agreement and very recently, they have sent us a large set of data (2.3 GB compressed zip file).  We have not yet performed a thorough examination of the data.  It consists of 1,673 images from the 1930 census with putative bounding boxes for the image regions where the features are to be extracted.  There are three distinct sets of labelings of all of the data of which we may make use (in order of labeling accuracy):
\begin{enumerate}
  \item A ground-truth set at 99.5\% accuracy
  \item A set that was indexed using the FamilySearch Indexing process: two independent manual indexers and an experienced arbitrator to handle conflicts \cite{hansen2013quality}
  \item Putative labeling from a separate company
\end{enumerate}
We have asked for, but have not yet received, some measure of the experience level or accuracy of the indexers from label set 2.  We hope to use cost-sensitive learning to give more credence to the labels given by the more accurate and experienced indexers and hopefully gain a better classifier than if we take labeled data set 2 as-is.  But for the easier fields we will begin with, this strategy may not have a significant impact.

Dustin Webb, a PhD. student, suggested for us to use a convolutional neural network deep learning algorithm.  There are many resources explaining convolutional neural networks including \cite{Bengio-et-al-2015-Book} \cite{kavukcuoglu2010learning} \cite{krizhevsky2012imagenet}.  One advantage of convolutional neural networks is its invariance to translation and its ability to handle variations in shape.  Dustin told us that it has historically performed very well with handwriting recognition and object recognition in image analysis in general.  An interesting aspect of convolutional neural networks in deep learning is that they learn their own sets of abstractions.  Instead of trying to come up with a complicated set of possibly relevant features, such as mean intensity, which horizontal half section has the majority of the handwritten pixels; instead of that, we can feed simply the pixel data and have the algorithm learn its own set of abstractions.  At least that's our understanding at the moment, which may leave much to be desired.

We were also pointed by Dustin Webb to the Theano python module for implementation of convolutional neural networks.  Theano takes mathematical expressions and compiles them into C++ to make for a robust and efficient framework \cite{bergstra+al:2010-scipy}.  We have gone through some of the tutorials of Theano on the \href{http://www.deeplearning.net}{deeplearning.net}.

\section{Future Plans}

Our first objective is to become more familiar with Theano and implementing convolutional neural networks.  We plan to use the MNIST data set to practice classifying handwritten digits using a convolutional neural network using Theano.  This will give us some experience using the tool on an easier problem.

The second objective is to improve our understanding of the basic concepts of deep learning and convolutional neural networks.  We will continue reading papers and Bengio's book on deep learning \cite{Bengio-et-al-2015-Book}.

We will then start working with the data presented to us by the Church.  We will want to see how the three distinct labelings differ for the record fields we want to start classifying.  It may be that they agree strongly for those fields, and disagree for more difficult fields such as name and place of birth.  But, if  these labeling sets differ significantly with the chosen fields, then we could maybe use that to our advantage somehow.

When training on this data set, we will first use the bounding boxes that they provide to us and train on a portion of the labeled data.  Originally we were going to use image processing and maybe even deep learning to determine where these bounding boxes are located.  We may still go down this path later and compare against the bounding boxes given to us.  But at least at the start, we won't.


\bibliographystyle{plain}
\bibliography{intermediate-report}

\end{document}

